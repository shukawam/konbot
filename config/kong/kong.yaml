_format_version: "3.0"
_transform: true

services:
  - name: chat-service
    host: httpbin.org
    port: 80
    protocol: http
    routes:
      - name: llm-route-openai
        paths:
          - ~/openai/(?<model>[^#?/]+)/chat/completions$
        strip_path: true
      - name: llm-route-cohere
        paths:
          - ~/cohere/(?<model>[^#?/]+)/chat/completions$
        strip_path: true

consumers:
  - username: free
    keyauth_credentials:
      - key: free-key
  - username: paid
    keyauth_credentials:
      - key: paid-key

plugins:
  ################
  # AI Gateway
  ################
  - name: ai-proxy
    route: llm-route-openai
    config:
      route_type: llm/v1/chat
      auth:
        header_name: Authorization
        header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
      logging:
        log_payloads: true
        log_statistics: true
      model:
        provider: openai
        name: $(uri_captures.model)
        options:
          input_cost: 0.15
          output_cost: 0.6
          max_tokens: 1024
          temperature: 0
          top_k: 100
          top_p: 0
  - name: ai-proxy
    route: llm-route-cohere
    config:
      route_type: llm/v1/chat
      auth:
        header_name: Authorization
        header_value: Bearer ${{ env "DECK_COHERE_API_KEY" }}
      logging:
        log_payloads: true
        log_statistics: true
      model:
        provider: cohere
        name: $(uri_captures.model)
        options:
          input_cost: 2.5
          output_cost: 10.0
          max_tokens: 1024
          temperature: 0
          top_k: 100
          top_p: 0
  - name: ai-prompt-decorator
    service: chat-service
    config:
      prompts:
        prepend:
          - role: system
            content: |
              あなたは賢いゴリラです。
              質問に対して必ずゴリラになりきって「ウホ」や「ゴリ」などの口調で回答してください。
  - name: ai-rag-injector
    service: chat-service
    config:
      embeddings:
        auth:
          header_name: Authorization
          header_value: Bearer ${{ env "DECK_OPENAI_API_KEY" }}
        model:
          provider: openai
          name: text-embedding-3-small
      vectordb:
        strategy: redis
        redis:
          host: redis
          port: 6379
        distance_metric: cosine
        dimensions: 1536
      vectordb_namespace: kong_rag_injector

  ################
  # Observability
  ################
  - name: opentelemetry
    config:
      traces_endpoint: http://otel-collector:4318/v1/traces
      logs_endpoint: http://otel-collector:4318/v1/logs
  - name: http-log
    config:
      http_endpoint: http://fluent-bit:2020
      custom_fields_by_lua:
        traceid: |
          local h = kong.request.get_header('traceparent')
          return h:match("%-([a-f0-9]+)%-[a-f0-9]+%-")
        spanid: |
          local h = kong.request.get_header('traceparent')
          return h:match("%-[a-f0-9]+%-([a-f0-9]+)%-")
  - name: prometheus
    config:
      per_consumer: true
      status_code_metrics: true
      ai_metrics: true
      latency_metrics: true
      bandwidth_metrics: true
      upstream_health_metrics: true
      # wasm_metrics: true

  ################
  # Security
  ################
  - name: key-auth
    service: chat-service
    config:
      key_names:
        - apikey
      hide_credentials: true
